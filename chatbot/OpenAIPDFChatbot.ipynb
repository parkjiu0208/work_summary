{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI pdf chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PDF 챗봇은 보통 다음과 같은 순서로 만들어진다.\n",
    "1. PDF 파일 로드\n",
    "2. 문서 텍스트 분할\n",
    "3. 벡터 임베딩\n",
    "4. 벡터 DB 생성 및 임베딩 값 저장\n",
    "\n",
    "   ----------------- 챗봇 구현 사전 단계 --------------------\n",
    "\n",
    "5. 사용자 질의를 임베딩 후 vector DB에서 검색 (Retriever 사용)\n",
    "6. QA Chain을 통해 LLM에서 답변을 생성받아 사용자에게 제공\n",
    "   - 프롬프트 엔지니어링\n",
    "   - llm 모델 정의\n",
    "   - (프롬포트-llm-출력) chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# API 키 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"],\n",
    ")\n",
    "\n",
    "text_chunks = [] \n",
    "for doc in docs:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    text_chunks.extend([Document(page_content=chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 데이터베이스 생성 및 벡터 임베딩\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever 정의\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_4732\\1498838928.py:16: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  \n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기후 공시는 기업이 기후변화 관련 정보를 공개하는 것을 말합니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"기후 공시가 뭐야?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
